---
permalink: /career/
title: "커리어"
excerpt: "난 개발자이다."
toc: true
---
# Lcventures 2016.09 ~ 2019.09

## 사내 카카오 마케팅팀 광고 단가 모니터링 서비스 개발(리메이크)

2018.11 ~ 2019.04

### - 프로젝트 시작 배경, 성과
카카오 모먼트의 데이터를 가져올 수 있는 API 제공하게 됨

크롤링으로 데이터를 가져왔던 기존 방식을 모두 버려야 함. 카카오 스토리&플러스 친구 크롤링은 제외

crawling server 에서 crontab 을 사용하여 크롤링하던 솔루션은 문제가 많았음

소스 코드 업데이트 하고 나면 50%는 이유를 알수 없는 서버 다운으로 잠 자는 동안 단가 측정이 안 됨. 당혹스러운 마케터들

코드에서 이슈가 발생하면 서버가 다운되어 아예 모든 크롤링이 안 됨. 디버깅이 참 귀찮고 쉽지 않음. 매번 서버에 일일이 소스 코드를 배포해야 하는 불편함. 그냥 서버 하나를 관리한다는 것 자체가 신경쓸게 많은 것 같음(난 비즈니스 로직만 신경쓰고 싶다...)

가즈아 서버리스

덕분에 퇴사 후, 현재까지도 무탈하게 잘 돌아감

단가 측정 기능 구현에 MSA 를 도입하여 새로운 기능 추가가 용이해짐, MSA 아키텍처, AWS Lambda 는 사랑입니다.

자동 입찰금 조정 기능을 추가하여, 자고 있는 사이 광고 성과가 망해버리는 초유의 사태를 완전히 없앰

### - 프로젝트 요약
 - 단가 측정 기능에 대한 MSA 설계
 - 카카오 API 연결하여 모먼트 데이터 가져오는 놈 / 카카오 스토리&플러스 친구에서 크롤링하여 데이터를 가져오는 놈 / 단가를 계산하는 놈 / DB에 데이터를 저장하는 놈 / 입찰금을 자동으로 조정하는 놈
 - 현재는 위와 같이 나뉘어져 있지 않다. API 로 데이터를 가져오고, 계산하고, DB에 저장하는 기능이 합쳐져 있다. 덕분에 Lambda 답지 않게 소스코드가 길어 가독성이 안 좋고 clod start 이슈가 있다. 물론 리팩토링 해야할 부분이다.
 - 각 기능별로 Lambda 를 만들고 boto3 를 이용하여 Lambda 와 Lambda 를 연결
 - SNS 에 G-Mail 을 Sub 하여 재빠르게 장애 대응. X-ray 는 아직 Lambda 의 갯수가 적어서 필요성을 못 느껴 사용하진 않았지만, 후에 Lambda 가 많아지면 기가 막힌 디버깅 서비스로 사용할 수 있을 듯.
 - 여기부터 슬슬 전의 EC2 를 Crawling Server 로 만들어서 사용하던 시절이 구석기 시대에 살았었구나를 느끼게 함.
 - asyncio, aiohttp 를 이용하여 concurrency 를 구현, concurrency.futures 의 ThreadPoolExecutor 보다 편했음. async/await 넘 좋다.
 - 카카오 API 를 0.1ms 미만의 속도로 여러번 요청하면 쓰로틀링에 걸린다. 어떤 광고는 잘 측정되고 어떤건 안 되는 난감한 상황 발생
 - 세마포어와 async.wait 를 적절히 사용하여 쓰로틀링이 걸리지 않은 선에서 최대한 동시에 요청할 수 있도록 구성. 어려운건 아니었지만 노가다하느라 많이 애먹음...
 - 원래는 API Gateway 를 이용하여 aiohttp 로 Lambda 를 호출하였으나, boto3 를 이용한 invoke 로 방식을 바꾸게 됨. API Gateway 는 Lambda 의 container 를 요청때마다 새로 생성. 2019년도 들어서 cold start 가 많이 감소 됐다지만 그래도 있는 건 있는 거다... boto3 를 이용하면 container 를 재사용 한다.
 - 자동 입찰 기능은 현재 단가가 안 좋을 경우 해당 광고의 입찰금을 10원씩 조정한다. 하지만 해당 광고 단가가 안 좋다고 광고안에서 운영되는 수많은 광고시안 각각의 입찰금을 모두 내리면 안 됨. 입찰금 조정이 시작되면 현재 광고시안 소진액과 지난 광고시안 소진액을 비교하여 변화폭이 큰 것만을 골라 입찰금을 조정해야 함. 문제는 카카오 API 가 현재의 광고시안 소진액만을 제공.
 - 위 문제를 해결하고자 DynamoDB 를 도입. 매 20분 마다 모든 광고시안의 소진액을 DynamoDB에 저장하는 Lambda 를 만듦.
 - DynamoDB를 사용한 이유는 다음과 같았다. 
    - 대량의 dict 형태의 데이터를 put 하고 입맛대로 쿼리하기에는 NoSQL 이 편했다. 그리고 SQL 문 안 짜도 된다. 스키마리스... NoSQL 의 대표 장점이라고나 할까. 적어도 내가 쓰는 용도에는 장점이 된다.  
    - 여러 NoSQL 이 있지만 DynamoDB 를 쓴 진짜 이유는!
    - DynamoDB의 데이터를 Lambda 에서만 사용하게 되는데, RDS 를 이용해야 할 경우 PyMySQL 를 사용해야 되지만 이건 그렇지 않아도 된다. boto3 는 빌트-인이다. 라이브러리 추가 안 해도 돼서 콜드 스타트에 조금의 이점도 생기지. (module 을 layers 로 분리 시켜도 Lambda 의 container 에는 같이 포함되기 때문에 cold start 가 줄진 않는다). 조금이라도 cold start 를 줄이고 싶었던 나의 욕망.
    - 그리고 거의 공짜로 쓸 수 있었다. 내 경우엔 SI를 따로 만든 것도 없고 LCU 가 작아서 그런지 월마다 0.25달러 정도의 요금밖에 안 나왔다.
    - stream 을 이용해서 활용할 수 있는 방안이 많다. stream Lambda 로 S3(혹은 다른 store 들)에 차곡차곡 쌓아서 후에 광고 분석을 위한 데이터로 써도 되고... RDS 와 하이브리드로 사용하여 RDS 를 쓰는 메인 프로젝트에서 핸들링이 쉬워지겠고... 등
 - 처음에는 lambda 를 콘솔을 이용하여 설정. 브라우저를 lambda 갯수 만큼 띄어 열심히 관리. 금방 적응하여 몇주는 이렇게 관리. 그러다가 내가 지금 뭐 하는 건가 싶음. 그리고 SAM 을 알게 됨.
 - SAM - AWS 의 서버리스 IaC 오픈소스 프로젝트(이것때문에 IaC 개념, CloudFormation 을 알게 됨). 몇 줄의 코드로 여러 Lambda 의 설정을 세팅하고 바로 배포 할 수 있음. 테스팅도 기가 맥힘.
 - 이후, Django 서버도 CloudFormation 스택으로 관리 시작. 더불어 Docker 세계에 진입. 이제 모든 시작은 Docker 로부터...  
 

## 사내 카카오 마케팅팀 광고 단가 모니터링 서비스 개발(리마스터)

2018.01 ~ 2018.03

### - 프로젝트 시작 배경, 성과
클릭스의 서비스 종료, 카카오의 모든 광고는 카카오 모먼트로 이관

광고 플랫폼이 바뀜에 따라 해당 플랫폼에 맞는 서비스 재구성 필요

이 프로젝트는 완성 했으나 사용하지 못하게 됨

카카오 쪽 제재로 해당 프로젝트 종료

### - 프로젝트 요약
 - Crawling Server 의 소스 코드 전부 변경
 - 기존 Selenium 소스 코드를 카카오 모먼트에 맞게 바꾸는 거라 큰 이슈는 없었음
 - 딱 한 가지가 있다면, Selenium 으로 로그인 처리하는 부분.
 - Selenium 엔 get cookie 기능이 있고 이걸 pickle 로 저장하고 재활용 하면 굳이 일일이 로그인 안 해도 된다는 기가 막힌 사실을 참 빨리도 깨달음.
 - 덕분에 연속 로그인을 하게 되면 캡차가 떠서 크롤링을 할 수 없었던 중요한 이슈를 해결하게 됨
 - 이후 또 한 가지 이슈 발생. 몇 시간 잘 크롤링 하다 보면 갑자기 카카오 모먼트 로그인 페이지 접속마저도 안 되어 크롤링이 안 됨. 카카오 쪽에서 IP 벤을 시키는 것 같았음. 
 - 질 수 없다. 난 꼭 크롤링 해야 한다. Proxy IP 를 써서 무사히 크롤링 진행. 또 문제 발생. cookie 를 이용하여 로그인 하고 다음 페이지로 리다이렉트 하면 페이지가 렌더링이 안 됨. 뒤로가기 하니까 정상적으로 리다이렉트. React 로 만든 것 같던데 어떤 라우팅 미들웨어를 설정했길래...
 - 무튼 해당 부분 해결하기 위해 정상 리다이렉트 될 때까지 뒤로가기 하도록 설정. 진짜 무사히 크롤링 진행.
 - 몇일 후 카카오 쪽에서 회사에 연락와 제재 조치. 이유는 카카오 서버에 과부화를 주어 카카오 모먼트의 전체 광고가 간헐적으로 정상 작동 하지 않았던 이슈 발생. 본의 아니게 해당 프로젝트가 ddos 공격 비슷한 상황을 연출시킴. 대행사 핸디캡 먹고 프로젝트 종료...
 - 카카오 같은 큰 회사가... 사실 아직도 이 부분은 의문임. 그래도 나의 이런 노고로 인해 카카오 모먼트 API 의 시발점이 됨.   
 - Django Server 의 소스 코드는 일부 변경(새로운 광고 플랫폼에 맞는 DB 스키마 변경과 UI 변경)

## 사내 카카오 마케팅팀 광고 단가 모니터링 서비스 개발(초기 버전)

2017.01 ~ 2017.04

### - 프로젝트 시작 배경, 성과
회사의 중요한 캐시카우 였던 카카오 마케팅팀을 위한 서비스

많은 수익을 올리는 팀 이었지만 거의 한 달 내내 야근을 함

이유는 주요 업무가 광고 시안 제작, 클라이언트 응대 및 가이드이나, 광고 단가를 수동으로 측정하느라 제때 주요 업무를 끝내지 못 하여 늘 야근 하게 됨(보통 마케터마다 5 ~ 15개의 클라이언트를 맞는데, 20분 마다 하나하나 클라이언트 수대로 카카오 스토리 소식 받기 수와 클릭스의 현재까지 소진액을 체크하여 구글 시트에 입력)

해당 업무 자동화 빠르게 필요

모든 마케터들과 현 업무 흐름에 대해 개인 인터뷰를 진행하고 내용을 정리하여 서비스 기획, 그리고 개발

모든 마케터들 단가 측정을 하는 업무에서 손을 때게되고 본연의 업무에 집중하게 됨, 업무의 새로운 패러다임 시작

늘어난 여유시간 만큼 더 많은 고객을 받게 되는 창조 경제 탄생, 야근은 그대로...

대신 주말에도 노트북 들고 늘 체크해야 하는 상황을 없앰으로써 적어도 주말은 편히 쉴 수 있게 됨

### - 프로젝트 요약
  - Django 의 시작
  - DB 는 MySQL! 광고 단가를 확인하는 페이지는 Django 로! 단가 계산 및 수집은 crontab 을 이용해 보자! 
  - 카카오 스토리 소싣 받기 수, 클릭스(과거 다음 광고 플랫폼)의 데이터를 크롤링하여 단가 계산 후 DB에 저장, ThreadPoolExecutor 사용하여 여러 광고 데이터를 통시에 크롤링하고 계산할 수 있도록 함
  - crontab 을 돌리는 동안 캐시 메모리가 쌓여 서버가 다운 되는 현상 발생, 주기적으로 캐시 메모리 정리할 수 있도록 crontab 설정
  - 해당 데이터를 시간 별로 확인할 수 있는 페이지 개발, 시간 별 데이터 표는 data table 를 이용

### - 프로젝트 요약
  - 웹 프레임워크로 Laravel 을 사용했다. 사용한 이유는 'PHP 가 생산성이 좋아서' 하나 였다. PHP 를 쓰긴 쓸 건데 웹 프레임워크로는 무엇을 만들어 볼까 고민하다 찾은게 Laravel 이다.
  - 기관에서 배운 Java 지식으로는 오랫 동안 안 해서 많이 까먹기도 했고 다시 공부해서 해야할 프로젝트를 소화하기가 겁이 났었다.
  - 한참 뒤에 깨달은 거지만, 그냥 기관에서 배운 Spring 지식 좀 더 공부해서 만들 껄 하는 후회를 했다. 어떤 언어든 깊이는 있고 제대로 쓸 줄 알아야 생산성이 좋은거다. 
  - 이 프로젝트는 만들면서 특별한 이슈가 있거나 이를 해결한 경험은 없었다. Laravel document 열심히 보며 MVC 패턴에 맞게 기획한 데로 프로젝트를 하나하나 빌딩해 나갔다.
  - 카페24에서 구매한 서버에 Nginx, php-fpm 을 설치하고, 개발한 프로젝트를 배포하였고, 잘 작동해 주었다. 이 또한, 구글링의 친절한 설명으로 잘 마무리 지었다. 난생 처음 만든 상용 서비스 였다.

## 랜딩 페이지 커스터 마이징 서비스(인포맥 - 초기 버전)

2016.09 ~ 2016.12

### - 프로젝트 시작 배경, 성과
광고 운영을 하기 위한 랜딩 페이지 수요가 많았고, 타사에서 만든 랜딩 페이지 커스터 마이징 서비스를 유료로 사용 중 이었음

대표님 왈 '돈 내고 쓰기 아깝다. 너가 똑같이 만들어 줘.'

저 회사에 Front-end 개발자로 들어왔는데요...?

이제 개발팀을 새로 꾸리는 회사에서 Front-end 개발만을 한다는게 말이 안 되긴 했다. 입사 하자마자 Back-end 개발의 시즈악.

그렇게 어려울 건 없었다. 그냥 똑같이 만들면 됐기에... 

완성은 했지만 반쪽짜리 완성이었다.

유료로 사용하던 비용을 절감하는 성과는 거뒀다. 그러나 너무 똑같이 만들었다. 

벤치마킹한 프로젝트가 앞으로의 비즈니스 요구사항을 소화할 수 없는 미완성이었다.

랜딩 페이지의 다양한 폼을 수용할 수 없었다. 

### - 프로젝트 요약
  - 웹 프레임워크로 Laravel 을 사용했다. 사용한 이유는 'PHP 가 생산성이 좋아서' 하나 였다. PHP 를 쓰긴 쓸 건데 웹 프레임워크로는 무엇을 만들어 볼까 고민하다 찾은게 Laravel 이다.
  - 기관에서 배운 Java 지식으로는 오랫 동안 안 해서 많이 까먹기도 했고 다시 공부해서 해야할 프로젝트를 소화하기가 겁이 났었다.
  - 한참 뒤에 깨달은 거지만, 그냥 기관에서 배운 Spring 지식 좀 더 공부해서 만들 껄 하는 후회를 했다. 어떤 언어든 깊이는 있고 제대로 쓸 줄 알아야 생산성이 좋은거다. 
  - 이 프로젝트는 만들면서 특별한 이슈가 있거나 이를 해결한 경험은 없었다. Laravel document 열심히 보며 MVC 패턴에 맞게 기획한 데로 프로젝트를 하나하나 빌딩해 나갔다.
  - 카페24에서 구매한 서버에 Nginx, php-fpm 을 설치하고, 개발한 프로젝트를 배포하였고, 잘 작동해 주었다. 이 또한, 구글링의 친절한 설명으로 잘 마무리 지었다. 난생 처음 만든 상용 서비스 였다.   

## 그 외 업무
- 사내 유통팀을 위한 발주서 통합 서비스 개발 > 하루 업무 시간의 2/3를 소비하던 발주서 정리를 3초만에 해결
- 사내 11번가 마케팅팀을 위한 판매자 정보 크롤링 서비스 개발 > 하루 업무 시간 1/3을 소비하던 판매자 정보 수집을 자동으로 처리해줌으로써 수집된 정보로 영업을 하는 데에만 집중할 수 있게 됨
- 카카오스토리 자동 댓글 서비스 개발 > 유통팀의 CRM 전략으로 사용
- 회사 홈페이지 관련 API (문의 하기 등) zappa 로 개발 > 불 필요한 서버 비용 절감
- 광고용 랜딩 페이지 다수 개발, html, css, js
- 광고 분석용 픽셀 코드 설치에 대한 고객사 가이드 및 설치를 위한 개발
- 사내 마케터 html, css, javascript 교육
- s3, route53을 이용하여 사내 CDN 구축 > 채용 공고 이미지, 제안서 등 사내에서 퍼블릭하게 이용하는 모든 자료 활용
- 인포맥 리메이크 기획 및 API 서버 개발, 비용 및 성능 개선
---
